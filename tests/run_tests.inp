clear
set verbose off
set assert stop

include "./src/knn.inp" --force
include CvDataSplitter.gfn
include extra.gfn

/*
##### Regression + no CV + different no. of neighbors
# Open dataset etc.
open credscore.gdt --quiet
# Parameters
matrix N_NEIGHBORS = seq(1, 3)
list x = Age Selfempl OwnRent
series y = Income
# Remove missing values and define training set
smpl y x --no-missing --permanent
bundle Model = knn_fit(y, x, N_NEIGHBORS)
print Model.rsq
print Model.ess
knn_summary(Model)


##### Cross-validation for regression using "loo" strategy
open credscore.gdt --quiet
# Set parameters
scalar N_NEIGHBORS = 7
string SPLITTERS = "loo"  # either "kfold", "loo"
bundle Params = _(splitters = SPLITTERS)
# Select features and target
list x = Age Selfempl OwnRent
series y = Income
# Fit the model
bundle Model = knn_fit(y, x, N_NEIGHBORS, Params)
knn_summary(Model)
Scores = Model.Scores  # nelme(array) == no. of Ks passed to knn_fit
assert(nelem(Scores) == nelem(N_NEIGHBORS))
assert(rows(Scores[1]) == $nobs)


##### Cross-validation for regression using "kfold" strategy
open credscore.gdt --quiet
# Set parameters
scalar N_NEIGHBORS = 7
scalar KFOLD_NSPLITS = 2
string SPLITTERS = "kfold"  # either "kfold", "loo"
bundle Params = _(splitters = SPLITTERS, kfold_nsplits = KFOLD_NSPLITS)
# Select features and target
list x = Age Selfempl OwnRent
series y = Income
# Fit the model
bundle Model = knn_fit(y, x, N_NEIGHBORS, Params)
Scores = Model.Scores
print Scores
assert(nelem(Scores) == nelem(N_NEIGHBORS))
assert(rows(Scores[1]) == KFOLD_NSPLITS)


##### Cross-validation for regression using "recwin" strategy for time-series
open denmark.gdt --quiet
# Set parameters
N_NEIGHBORS = 3
scalar WIN_SIZE = 32
string SPLITTERS = "recwin"  # either "kfold", "loo"
bundle Params = _(splitters = SPLITTERS, win_size = WIN_SIZE)
# Select features and target
list x = ldiff(LRY) diff(IBO)
series y = ldiff(LRM)
smpl y x --no-missing
# Fit the model
bundle Model = knn_fit(y, x, N_NEIGHBORS, Params)
print Model
knn_summary(Model)
Scores = Model.Scores
matrix scores = Scores[1]
print scores
boxplot 2 --matrix=scores --output=display {set title "Distribution of RMSE across folds";}

##### Cross-validation for regression using "kfold" strategy
##### plus various no. of neighbors
open credscore.gdt --quiet
# Set parameters
matrix N_NEIGHBORS = seq(1, 20)
scalar KFOLD_NSPLITS = 5
string SPLITTERS = "kfold"  # either "kfold", "loo"
string METRIC = "mae"
bundle Params = _(splitters = SPLITTERS, kfold_nsplits = KFOLD_NSPLITS,
                  scoring_regression = METRIC)
# Select features and target
list x = Age Selfempl OwnRent
series y = Income
# Fit the model
bundle Model = knn_fit(y, x, N_NEIGHBORS, Params)
print Model
knn_summary(Model)
print Model.mean_scores
knn_plot_score(Model)
*/


#/*
#####################################
### Classification using cross-validation
# Run k-fold with 5 folds sampling
#####################################
open credscore.gdt --quiet
# Set parameters
matrix NEIGHBORS = seq(1, 7)  # sequence of no. of neighbors to evaluate
scalar KFOLD_NSPLITS = 5  # only relevant for splitters = "kfold"
string SPLITTERS = "kfold"  # only either "kfold", "loo" not supported, yet
string METRIC = "PRC"
bundle Params = _(splitters = SPLITTERS, kfold_nsplits = KFOLD_NSPLITS,
                  scoring_classification = METRIC)
# Select features and target
list x = Income Age Selfempl OwnRent
series y = Age
# !!!Make sure, the target is recognized as being discrete!!!
setinfo y --discrete

# FIXME: Some scores increase in performance but some decrease
# You need to compute the inverse of increasing ones before looking for
# the minimum!

# Fit the model
bundle Model = knn_fit(y, x, NEIGHBORS, Params)
knn_summary(Model)
knn_plot_score(Model)
print Model.Scores[1]
print Model.Scores[4]
print Model.mean_scores
#*/


##############
# WBG example
##############
open \
  /home/artur/Universit√§t/THB/Kooperationen/WBG/WBG_Datensatz_valide_NA_Werte.xlsx --quiet

list x = WohnflAche Wohngebiet Haustier
series y = Geschlecht
setinfo y --discrete

smpl obs < 200 --restrict --permanent

# Parameter
scalar N_NEIGHBORS = 2
scalar SHARE_TESTSET = 1/2
# Remove missing values
smpl y x --no-missing --permanent
# Define training set
series rand = randgen(i, 0, 1)
series trainset = (rand >= SHARE_TESTSET) ? TRUE : FALSE

# No cross-validation
bundle Model = knn_fit(y, x, N_NEIGHBORS)
knn_summary(Model)  # Print summary of estimation
series yhat = Model.yhat
summary y yhat
xtab y yhat
print knn_scores(y, yhat, Model)

# With cross-validation
smpl trainset == TRUE --restrict --replace
matrix NEIGHBORS = seq(1, 4)  # sequence of no. of neighbors to evaluate
scalar KFOLD_NSPLITS = 3    # only relevant for splitters = "kfold"
string SPLITTERS = "kfold"  # only either "kfold", "loo" not supported, yet
bundle Params = _(kfold_nsplits = KFOLD_NSPLITS, splitters = SPLITTERS)
bundle Model = knn_fit(y, x, NEIGHBORS, Params)
knn_summary(Model)
knn_plot_score(Model)



print "Finished all tests succesfully."
quit
