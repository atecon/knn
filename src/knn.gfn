<?xml version="1.0" encoding="UTF-8"?>
<gretl-functions>
<gretl-function-package name="knn" minver="2024a">
<author email="atecon@posteo.de">Artur Tarassow</author>
<version>0.1</version>
<date>2024-05-21</date>
<description>KNN regression and classification estimator</description>
<tags>C13 C52</tags>
<help filename="knn_help.md">
# KMeans Package

This package includes functionalities to identify unknown clusters of multidimensional data using the well known (at least in the machine-learning field) knn algorithm.

The knn algorithm divides a set of `N` samples `X` into `k` disjoint clusters `C`, each described by the mean of the samples in the cluster. The means are called the cluster centroids.

The objective is to minimize some loss. For instance, the objective is to minimize &quot;inertia&quot;, or within-cluster sum-of-squares criterion in case of the Euclidean distance function.

For more information see:

https://scikit-learn.org/stable/modules/clustering.html#knn

Please ask questions and report bugs on the Gretl mailing list if possible. Alternatively, create an issue ticket on the github repo (see below).
Source code and test script(s) can be found here: https://github.com/atecon/knn


## GUI access

The dialog box can be opened via `View -&gt; k-Means`.


# Public Functions

## knn_fit

```
knn_fit (const list xlist, const int n_clusters[2::2], bundle opts[null])
```

Execute the knn algorithm and estimate the clusters.

**Arguments:**

- `xlist`: list, Features (regressors) to train the model.
- `n_clusters`: int, Number of assumed clusters (default: 2)
- `opts`: bundle, Optional parameters affecting the knn algorithm. You can pass the following parameters:

    * `algorithm`: string, knn algorithm to use. Currently, only `full` is supported (classical EM-style algorithm).
    * `distance_type`: string, Name of the distance metric applied (default: `euclidean`). For more distance metrics, see gretl's built-in function `distance()`.
    * `initializer`: string, Method for initialization. Either `random`: Choose `n_clusters` observations (rows) at random from data for the initial centroids. Or `pca`: Try to pick data points that are as far apart as possible by means of PCA.
    * `max_iter`: int, Maximum number of iterations of the knn algorithm to run.
    * `n_draws`: int, Number of time the knn algorithm will be run with different centroid seeds. The final results will be the best output of `n_draws` consecutive runs in terms of inertia.
    * `tolerance`:  scalar, Minimum improvement of the `within_variation_total` (Sum of the squared distances across all clusters) required before early stopping the algorithm (default: 1e-4)
    * `verbose`: int, Level of verbosity: `0`: don't print anything, `1`: print some details, `2`: print more details (default: `0`)


**Return:** Bundle holding various items.

- `between_variation`: scalar, Between cluster sum of squares = `total_ssq - within_variation_total`
- `centroids`: matrix, Estimated mean values (centroids) for each feature (columns) and for each cluster (rows).
- `cluster_id`: matrix, Estimated cluster ID for each observation for the best draw minimizing `inertia`.
- `distances`: matrix, Estimated distance for the best draw minimizing `inertia`.
- `error`: int, Error code. In case of no error `FALSE`, otherwise positive integer.
- `nobs`: int, Number of non-missing observations used for training.
- `pointsize`: scalar, Size of points being plotted when calling the `knn_plot()` function.
- `total_ssq`: scalar, Sum of the squared distances of the features from its mean values
- `use_circles`: bool, Plot circles instead of point when calling the `knn_plot()` function.
- `within_variation_total`: scalar, Sum of the squared distances across all clusters.
- `within_variation_avg`: scalar, Sum of the average squared distances across all clusters.


## knn_predict

```
knn_predict (const list xlist, const bundle Model)
```

Predict cluster belonging based on the estimated model.

**Arguments:**

- `xlist`: list, Features (regressors) used for predicting cluster belonging.
- `Model`: bundle, Model object returned by the `knn_fit()` function.

**Return:** Series holding the predicted cluster ID for each observation.


## knn_summary

```
knn_summary (const bundle Model)
```

Print summarizing information on estimation step after having applied the `knn_fit()` function.

**Arguments:**

- Model: bundle, Bundle returned by the `knn_fit()` function.

**Return:** Nothing.


## knn_plot

```
knn_plot (const list xlist, const bundle self[null])
```

Factorized scatter plot estimated clusters for each 2-dimensional combination of features. This function calls the user-defined package &quot;PairPlot&quot; which must be installed.

**Arguments:**

- `xlist`: list, Features (regressors) used for plotting.
- `self`: bundle, Bundle for manipulating the plot. **Note** Here you can also pass options accepted by the &quot;PairPlot&quot; package which is used in the background.

**Return:** Nothing.


# Changelog

* **v0.3 (February 2024)**
    * Add GUI dialog
    * Move to markdown-based help file
    * Internal improvements

* **v0.2 (July 2022)**
    * Fix bug that arises if the sample range is restricted, and you're trying to coerce a column vector that's not the full length of the dataset into a series on adding it to a bundle.
    * Returned objects `cluster_id` and `distances` when calling the `knn_fit()` function are of type matrix instead of series, now.

* **v0.1 (February 2022)**
    * initial release
</help>
<depends count="2">
extra FEP </depends>
<gretl-function name="knn_fit" type="bundle">
 <params count="4">
  <param name="y" type="series" const="true">
<description>Target</description>
  </param>
  <param name="xlist" type="list" const="true">
<description>Features</description>
  </param>
  <param name="n_neighbors" type="int" min="1" default="5" const="true">
<description>No. of neighbors</description>
  </param>
  <param name="opts" type="bundle" optional="true">
<description>Parameter bundle</description>
  </param>
 </params>
<code>/* Function for computing KNN: run the setup and train the model. */

check_required_pkg_version()

if !exists(opts)
  bundle opts = defbundle()
endif

list L = y xlist
errorif(sum(missing(L)), &quot;Some  have missing values. Please drop these first.&quot;)
errorif($nobs &lt;= n_neighbors, &quot;Number of rows must exceed number of neighbors.&quot;)

bundle self = set_bundle_and_get_defaults(xlist, opts)
self.distance_type = tolower(self.distance_type)
scalar self.n_neighbors = n_neighbors
string self.depvar = argname(y)
strings self.parnames = varnames(xlist)
string self.type = getinfo(y).discrete == TRUE ? &quot;classification&quot; : &quot;regression&quot;
matrix self.features = prepare_features(xlist, self.stdize_features)
matrix self.target = {y}

matrix distances = compute_distances(self.features)
# Compute the indices for each observation which are the closest to it
matrix indices_of_closest = indices_of_closest(distances, self.n_neighbors)
# Compute the predictions for the target using data on the closest neighbors
if self.type == &quot;regression&quot;
  matrix self.yhat = compute_yhat_regression(self.target, indices_of_closest)
else
  matrix self.yhat = compute_yhat_classification(self.target, indices_of_closest, self.class_prediction)
endif

matrix self.uhat = self.target - self.yhat

if self.type == &quot;regression&quot;
  # TODO: also valid for classification?
  scalar self.rsq = get_rsq(self.target, self.yhat)
  scalar self.ess = sst(self.uhat)
endif

return self
</code>
</gretl-function>
<gretl-function name="knn_predict" type="matrix">
 <params count="2">
  <param name="self" type="bundle" const="true"/>
  <param name="X" type="numeric" const="true"/>
 </params>
<code>/*
This function performs k-nearest neighbors prediction on new data points.

Parameters:
- self: The bundle containing the training data and model parameters.
- X: The new data points to be predicted.

Returns:
- prediction: The predicted values for the new data points.

Notes:
- The function checks if the number of columns in the new data points matches the number of columns in the training data.
- The function prepares the new data points by standardizing the features if required.
- The function computes the distances between the new data points and the training data.
- The function selects the closest neighbors for each new data point.
- The function computes the predicted values based on the type of problem (regression or classification).
*/

if typename(X) == &quot;series&quot; || typename(X) == &quot;list&quot;
  matrix new_data = {X}
else
  matrix new_data = X
endif

errorif(cols(new_data) != cols(self.features), &quot;The number of columns in the new data points does not match the number of columns in the training data.&quot;)
scalar nX = rows(new_data)
matrix new_data = prepare_features(new_data, self.stdize_features)
matrix new_data |= self.features

matrix distances = compute_distances(new_data)
# Remove the initial nX columns which are the distances to themselves
# Keep only the initial nX rows which are the distances for the nX testdata records
distances = distances[1:nX,-seq(1,nX)]

# Compute the indices for each observation which are the closest to it
matrix indices_of_closest = indices_of_closest(distances, self.n_neighbors)

# Compute the predictions for the target using data on the closest neighbors
if self.type == &quot;regression&quot;
  matrix prediction = compute_yhat_regression(self.target, indices_of_closest)
else
  matrix prediction = compute_yhat_classification(self.target, indices_of_closest, self.class_prediction)
endif

return prediction
</code>
</gretl-function>
<gretl-function name="knn_scores" type="matrix">
 <params count="3">
  <param name="actual" type="numeric" const="true"/>
  <param name="pred" type="numeric" const="true"/>
  <param name="self" type="bundle" const="true"/>
 </params>
<code>/*
Function: knn_scores

Calculates the forecast statistics for the k-nearest neighbors (kNN) algorithm.

Parameters:
actual (numeric): The actual target variable values. Can be a series or a column vector.
pred (numeric): The predicted target variable values. Can be a series or a column vector.
self (bundle): A bundle containing additional information about the algorithm.

Returns:
fcstats (matrix): The forecast statistics matrix.

Notes:
- The target variable must be either a series or a column vector.
- The prediction variable must be either a series or a column vector.
- The bundle 'self' must contain the following properties:
- type (string): The type of the algorithm ('regression' or 'classification').
- class_prediction (string): The method used for class prediction in case of classification ('majority' or 'probability').
*/

if typename(actual) == &quot;list&quot; || typename(pred) == &quot;list&quot;
  errorif(TRUE, &quot;The actual and prediction variable must be either a series or a column vector.&quot;)
endif

if typename(actual) == &quot;series&quot;
  matrix target = {actual}
else
  matrix target = actual
endif

if typename(pred) == &quot;series&quot;
  matrix prediction = {pred}
else
  matrix prediction = pred
endif

if self.type == &quot;regression&quot;
  matrix fcstats = fcstats(target, prediction)
elif self.type == &quot;classification&quot;
  if self.class_prediction == &quot;majority&quot;
    matrix fcstats = fcstats_majority(target, prediction)
  elif self.class_prediction == &quot;probability&quot;
    matrix fcstats = fcstats_probability(target, prediction)
  endif
endif

return fcstats
</code>
</gretl-function>
<gretl-function name="knn_summary" type="void">
 <params count="1">
  <param name="self" type="bundle" const="true"/>
 </params>
<code># print summary of the model
printf &quot;\nK-Nearest Neighbors Model Summary\n&quot;
printf &quot;----------------------------------\n&quot;
printf &quot;Type:                    %s\n&quot;, self.type
printf &quot;Number of neighbors:     %d\n&quot;, self.n_neighbors
printf &quot;Distance type:           %s\n&quot;, self.distance_type
printf &quot;Standardize features:    %s\n&quot;, self.stdize_features ? &quot;Yes&quot; : &quot;No&quot;
printf &quot;Target variable:         %s\n&quot;, self.depvar
printf &quot;Feature variables:       %s\n&quot;, flatten(self.parnames, &quot;, &quot;)
printf &quot;Number of observations:  %d\n&quot;, self.nobs
printf &quot;Sample period:           %d to %d\n&quot;, self.sample_t1, self.sample_t2

if self.type == &quot;regression&quot;
  printf &quot;R-squared:              %.4f\n&quot;, self.rsq
  printf &quot;Sum of squares:         %.4f\n&quot;, self.ess
endif
printf &quot;----------------------------------\n&quot;
</code>
</gretl-function>
<gretl-function name="set_bundle_and_get_defaults" type="bundle" private="1">
 <params count="2">
  <param name="xlist" type="list" const="true"/>
  <param name="opts" type="bundle" optional="true"/>
 </params>
<code>/* Compile self bundle by merging eventual information
from 'opts' bundle. */

if !exists(opts)
  bundle opts = defbundle()
endif

bundle self = default_values(xlist)
self = opts + self          # override defaults

return self
</code>
</gretl-function>
<gretl-function name="default_values" type="bundle" private="1">
 <params count="1">
  <param name="xlist" type="list" const="true"/>
 </params>
<code>/* Set default values. */

bundle self = defbundle()
scalar self.stdize_features = TRUE
scalar self.error = FALSE
scalar self.verbose = 1
string self.distance_type = &quot;euclidean&quot;
string self.class_prediction = &quot;majority&quot;  # probability
scalar self.nobs = $nobs
scalar self.sample_t1 = $t1
scalar self.sample_t2 = $t2

return self
</code>
</gretl-function>
<gretl-function name="check_required_pkg_version" type="void" private="1">
<code>/* Check if installed dependencies fulfill version requirements. */

pkg query PairPlot --quiet
errorif($result.version &lt; 0.8, sprintf(&quot;Please update the 'PairPlot' package to at least version 0.8.\n\ The hansl command is 'pkg install PairPlot'&quot;) )
</code>
</gretl-function>
<gretl-function name="compute_distances" type="matrix" private="1">
 <params count="1">
  <param name="features" type="matrix" const="true"/>
 </params>
<code>/* Compute distance matrix */

matrix out = distance(features)
matrix D = unvech(out, 0)

return D
</code>
</gretl-function>
<gretl-function name="fcstats_majority" type="matrix" private="1">
 <params count="2">
  <param name="actual" type="matrix" const="true"/>
  <param name="prediction" type="matrix" const="true"/>
 </params>
<code>/**
* Compute evaluation statistics for binary integer outcomes.
*
* actual: The matrix of true actual values.
* prediction: The matrix of predicted values.
* return: The matrix of evaluation statistics, including false rate, hit rate, and Kuipers score.
*/

bundle B = _(yup = actual, fcup = prediction)
doKS(&amp;B)
matrix fcstats = B.KSfalse | B.KShit | B.KSstat
rnameset(fcstats, defarray(&quot;false-rate&quot;, &quot;hit-rate&quot;, &quot;Kuipers-score&quot;))

# FIXME: Results do not coincide. Check which function returns wrong values.
#matrix scores = scores2x2(actual ~ prediction, FALSE)

return fcstats
</code>
</gretl-function>
<gretl-function name="fcstats_probability" type="matrix" private="1">
 <params count="2">
  <param name="actual" type="matrix" const="true"/>
  <param name="prediction" type="matrix" const="true"/>
 </params>
<code>/*
* This function computes evaluation statistics for binary classification models.
*
* Parameters:
* - actual: A matrix containing the actual class labels.
* - prediction: A matrix containing the predicted probabilities for each class.
*
* Returns:
* - fcstats: A matrix containing the evaluation statistics (computed by the &quot;FEP&quot; package).
*   - If the number of unique values in 'actual' is 2, the column vector
*     contains the following statistics:
*     - Quadratic probability score (QPS)
*     - Logarithmic probability score (LPS)
*   - If the number of unique values in 'actual' is not 2, a warning message is printed and an empty matrix is returned.
*/

if nelem(values(actual)) == 2
  matrix fcstats = probscore(actual, prediction)
  strings label = cnameget(fcstats)
  fcstats = fcstats'
  rnameset(fcstats, label)
else
  printf &quot;\nWARNING: No support for statistics for more than three class outcomes.\n\n&quot;
  matrix fcstats = {}
endif

return fcstats
</code>
</gretl-function>
<gretl-function name="prepare_features" type="matrix" private="1">
 <params count="2">
  <param name="xlist" type="numeric" const="true"/>
  <param name="stdize_features" type="bool" const="true"/>
 </params>
<code>if typename(xlist) == &quot;series&quot; || typename(xlist) == &quot;list&quot;
  matrix features = {xlist}
else
  matrix features = xlist
endif

if stdize_features
  matrix features = stdize(features, 0, TRUE)
endif

return features
</code>
</gretl-function>
<gretl-function name="get_rsq" type="scalar" private="1">
 <params count="2">
  <param name="target" type="matrix" const="true"/>
  <param name="yhat" type="matrix" const="true"/>
 </params>
<code>/*
* Calculates the R-squared value between the target and predicted values.
*
* target: The matrix of target values.
* yhat: The matrix of predicted values.
* return: The R-squared value.
*/
scalar rsq = mcorr(target~yhat)[1,2]^2
return rsq
</code>
</gretl-function>
<gretl-function name="compute_yhat_regression" type="matrix" private="1">
 <params count="2">
  <param name="target" type="matrix" const="true"/>
  <param name="indices_of_closest" type="matrix" const="true"/>
 </params>
<code>/*
* Compute the predicted values (yhat) based on the target matrix and
* the indices of the closest neighbors for regressions.
*
* target: The target matrix containing the true values.
* indices_of_closest: The matrix containing the indices of the closest neighbors.
*
* return: The matrix containing the predicted values (yhat).
*/

matrix yhat = target_means(target, indices_of_closest)
return yhat
</code>
</gretl-function>
<gretl-function name="compute_yhat_classification" type="matrix" private="1">
 <params count="3">
  <param name="target" type="matrix" const="true"/>
  <param name="indices_of_closest" type="matrix" const="true"/>
  <param name="class_prediction" type="string" const="true"/>
 </params>
<code>/*
* Compute the predicted values (yhat) based on the target matrix and
* the indices of the closest neighbors for classification.
*
* target: The target matrix containing the true values.
* indices_of_closest: The matrix containing the indices of the closest neighbors.
*
* return: The matrix containing the predicted values (yhat).
*/

matrix yhat = target_class(target, indices_of_closest, class_prediction)

return yhat
</code>
</gretl-function>
<gretl-function name="target_means" type="matrix" private="1">
 <params count="2">
  <param name="target" type="matrix" const="true"/>
  <param name="indices_of_closest" type="matrix" const="true"/>
 </params>
<code>/*
* Calculates the mean values of the target variable for each observation
* based on the indices of the closest neighbors.
*
* target: The matrix containing the target variable values.
* indices_of_closest: The matrix containing the indices of the closest
neighbors for each observation.

* return: The matrix of mean values of the target variable for each observation.
*/

scalar N = $nobs
matrix yhat = mshape(NA, N, 1)

loop i = 1..N
  matrix idx = indices_of_closest[,i]
  matrix yhat[i] = mean(target[idx])
endloop

return yhat
</code>
</gretl-function>
<gretl-function name="target_class" type="matrix" private="1">
 <params count="3">
  <param name="target" type="matrix" const="true"/>
  <param name="indices_of_closest" type="matrix" const="true"/>
  <param name="class_prediction" type="string" const="true"/>
 </params>
<code>/*
* This function calculates either the mode or conditional probability of the target
* variable for each observation based on the indices of the closest neighbors.
*
* Parameters:
* - target: A matrix containing the target variable values for all observations.
* - indices_of_closest: A matrix containing the indices of the closest
*   neighbors for each observation.
* - class_prediction: Type of prediction; either `majority` or `probability`.
*
* Returns:
* - yhat: A matrix containing either the mode or conditional probability of
*   the target variable for each observation.
*/

scalar N = $nobs
matrix yhat = mshape(NA, N, 1)
scalar information = class_prediction == &quot;majority&quot; ? 1 : 2

loop i = 1..N
  matrix idx = indices_of_closest[,i]
  matrix value = onemode(target[idx])[information]

  if ok(value)
    matrix yhat[i] = value
  else
    printf &quot;WARNING: Could not compute prediction for observation %d. Ignore.\n&quot;, $i
  endif
endloop

return yhat
</code>
</gretl-function>
<gretl-function name="indices_of_closest" type="matrix" private="1">
 <params count="2">
  <param name="distances" type="matrix" const="true"/>
  <param name="n_neighbors" type="int" const="true"/>
 </params>
<code>/*
This function calculates the indices of the closest neighbors based on the given distances.

Parameters:
- distances: matrix, the distances between observations.
- n_neighbors: int, the number of closest neighbors to consider.

Returns:
- idx: matrix, the indices of the closest neighbors (in rows) for each
observation (in columns). The rows equal the number of neighbors.
*/

scalar N = rows(distances)
matrix indices_of_closest = mshape(NA, n_neighbors, N)
matrix idx = seq(1, cols(distances))'  # TODO: check if the index respects NA values in data

# TODO: Check whether this can be improved in terms of computation
# TODO: In principle this may be parallelized

loop i = 1..N
  matrix row = distances[i,]' ~ idx
  # sort by distance in ascending order
  matrix sorted = msortby(row, 1)[-i,]  # remove reference observation
  matrix indices_of_closest[,i] = sorted[1:n_neighbors, 2]
endloop

return indices_of_closest
</code>
</gretl-function>
<sample-script>
clear
set verbose off
include knn.gfn

open credscore.gdt --quiet

# Select an example to run
EXAMPLE = 1

if EXAMPLE == 1  # regression
    list x = Age
    series y = Income
elif EXAMPLE == 2  # classification
    list x = Age Income
    series y = Acc
    setinfo y --discrete
    bundle Params = _(class_prediction = &quot;probability&quot;)
endif

# Parameter
scalar N_NEIGHBORS = 5

# Remove missing values and define training set
smpl y x --no-missing --permanent
genr index
series trainset = (index &lt;= 50) ? TRUE : FALSE

# Activate training set
smpl trainset == TRUE --restrict

# Euclidean distance (default)
# ============================
bundle Model = knn_fit(y, x, N_NEIGHBORS)#, Params)
knn_summary(Model)  # Print summary of estimation
stop

series yhat = Model.yhat
series uhat = Model.uhat

if EXAMPLE == 1
    series diagonal = y
    gnuplot yhat diagonal y --with-lines=diagonal --output=display \
      {set yrange[0:10]; set xrange[0:10];}

    freq uhat --normal --plot=display

elif EXAMPLE == 2
    if Model.class_prediction == &quot;majority&quot;
        gnuplot Age Avgexp yhat --dummy --output=display --fit=none
    endif
endif

# In-sample scores
print knn_scores(y, yhat, Model)

# Activate testset and predict out-of-sample
smpl trainset == FALSE --restrict --replace
series prediction = knn_predict(Model, x)
# Out-of-sample scores
print knn_scores(y, prediction, Model)
print y prediction -o --range=:10

stop



/*
# Determine the optimal number of cluster by means of a screeplot
# ===============================================================
scalar max_clusters = 5
matrix inertia = seq(2, max_clusters)' ~ mshape(NA, max_clusters - 1, 1)
cnameset(inertia, &quot;n_clusters inertia&quot;)

loop i=2..max_clusters
    bundle Model = knn_fit(x, $i)
    inertia[i-1, 2] = Model.within_variation_total
endloop

gnuplot 2 1 --matrix=inertia --with-lines --output=display \
    {set title 'Scree plot showing inertia as a function of no. of clusters'; }
*/
</sample-script>
</gretl-function-package>
</gretl-functions>
